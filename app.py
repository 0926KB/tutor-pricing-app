# app.py
import pandas as pd
import numpy as np
import re
import streamlit as st

from sklearn.linear_model import LinearRegression
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import OneHotEncoder
from sklearn.impute import SimpleImputer
from sklearn.compose import ColumnTransformer
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score

import gspread
from oauth2client.service_account import ServiceAccountCredentials
import csv
from datetime import datetime

# =============================
# Streamlit ê¸°ë³¸ ì„¤ì •
# =============================
st.set_page_config(page_title="í”„ë¦¬ëœì„œ ê°•ì‚¬ ì‹œê¸‰ ì˜ˆì¸¡ê¸°", page_icon="ğŸ’°", layout="centered")

RAW_FILE = "survey.csv"

# =============================
# ëŒ€í•™ ë¶„ë¥˜ í…Œì´ë¸” & í•¨ìˆ˜
# =============================
UNIV_TABLE = {
    # ---- Tier A (3ì ) ----
    "ì„œìš¸ëŒ€í•™êµ": {"keywords": ["ì„œìš¸ëŒ€í•™êµ", "ì„œìš¸ëŒ€", "snu"], "tier": "A", "score": 3},
    "ì—°ì„¸ëŒ€í•™êµ": {"keywords": ["ì—°ì„¸ëŒ€í•™êµ", "ì—°ì„¸ëŒ€", "yonsei"], "tier": "A", "score": 3},
    "ê³ ë ¤ëŒ€í•™êµ": {"keywords": ["ê³ ë ¤ëŒ€í•™êµ", "ê³ ë ¤ëŒ€"], "tier": "A", "score": 3},
    # ---- Tier B (2ì ) ----
    "ì„±ê· ê´€ëŒ€í•™êµ": {"keywords": ["ì„±ê· ê´€ëŒ€í•™êµ", "ì„±ê· ê´€ëŒ€"], "tier": "B", "score": 2},
    "í•œì–‘ëŒ€í•™êµ": {"keywords": ["í•œì–‘ëŒ€í•™êµ", "í•œì–‘ëŒ€"], "tier": "B", "score": 2},
    "ê²½í¬ëŒ€í•™êµ": {"keywords": ["ê²½í¬ëŒ€í•™êµ", "ê²½í¬ëŒ€"], "tier": "B", "score": 2},
    "ì´í™”ì—¬ìëŒ€í•™êµ": {"keywords": ["ì´í™”ì—¬ìëŒ€í•™êµ", "ì´í™”ì—¬ëŒ€"], "tier": "B", "score": 2},
    # ---- Tier C (1ì ) : ì˜ˆì‹œë¡œ ì¼ë¶€ ì¶”ê°€, í•„ìš”ì‹œ í™•ì¥ ----
    "ì„œê°•ëŒ€í•™êµ": {"keywords": ["ì„œê°•ëŒ€í•™êµ", "ì„œê°•ëŒ€"], "tier": "C", "score": 1},
    "ì¤‘ì•™ëŒ€í•™êµ": {"keywords": ["ì¤‘ì•™ëŒ€í•™êµ", "ì¤‘ì•™ëŒ€"], "tier": "C", "score": 1},
    "í•œêµ­ì™¸êµ­ì–´ëŒ€í•™êµ": {"keywords": ["í•œêµ­ì™¸êµ­ì–´ëŒ€í•™êµ", "í•œêµ­ì™¸ëŒ€", "hankuk"], "tier": "C", "score": 1},
    "ë™êµ­ëŒ€í•™êµ": {"keywords": ["ë™êµ­ëŒ€í•™êµ", "ë™êµ­ëŒ€"], "tier": "C", "score": 1},
    "í™ìµëŒ€í•™êµ": {"keywords": ["í™ìµëŒ€í•™êµ", "í™ìµëŒ€"], "tier": "C", "score": 1},
}

DEFAULT_UNIV = {"name": "ê¸°íƒ€", "tier": "D", "score": 0}

def classify_univ(raw_name: str):
    """raw_name -> (í‘œì¤€í™”ëœ í•™êµëª…, í‹°ì–´ë¬¸ì, ì ìˆ˜)"""
    if not raw_name:
        return DEFAULT_UNIV["name"], DEFAULT_UNIV["tier"], DEFAULT_UNIV["score"]
    text = re.sub(r"[^\w\s]", "", str(raw_name).lower())
    for uni_name, info in UNIV_TABLE.items():
        for kw in info["keywords"]:
            if kw.lower() in text:
                return uni_name, info["tier"], info["score"]
    return DEFAULT_UNIV["name"], DEFAULT_UNIV["tier"], DEFAULT_UNIV["score"]

# =============================
# ë°ì´í„° ì •ì œ
# =============================
@st.cache_data
def clean_data(csv_path: str):
    df = pd.read_csv(csv_path)

    # ì‹œê¸‰ ì •ì œ
    def clean_hourly_won(text):
        if pd.isna(text):
            return np.nan
        text = str(text).strip()
        if text.replace(".", "", 1).isdigit():
            val = float(text)
            if val <= 10:
                return int(val * 10000)
            elif val < 300:
                return int(val * 100)
            else:
                return int(val)
        numbers = [int(n.replace(",", "")) for n in re.findall(r"\d{2,3},?\d{3}", text)]
        numbers = [n for n in numbers if n >= 1000]
        return int(np.mean(numbers)) if numbers else np.nan

    df["hourly_won_clean"] = df["ë³¸ì¸ì˜ ì‹œê¸‰ì„ ì…ë ¥í•´ì£¼ì„¸ìš”. (ì›)"].apply(clean_hourly_won)
    df["log_hourly_won_clean"] = df["hourly_won_clean"].apply(lambda x: np.log1p(x) if pd.notna(x) else np.nan)

    # ì „ê³µ ì—°ê´€ì„± ë¼ë²¨
    score_to_label = {"1": "E", "2": "D", "3": "C", "4": "B", "5": "A"}
    df["major_match_label"] = df["ì „ê³µê³¼ ê°€ë¥´ì¹˜ëŠ” ê³¼ëª©ì´ ì–¼ë§ˆë‚˜ ê´€ë ¨ì´ ìˆë‚˜ìš”?"].astype(str).map(score_to_label)

    # ê²½ë ¥ ë¼ë²¨
    def normalize_experience(val):
        if pd.isna(val):
            return None
        s = str(val).strip().replace(" ", "")
        if "1ë…„ì´í•˜" in s:
            return "1ë…„ ì´í•˜"
        if "1~2ë…„" in s or "1ë…„~2ë…„" in s:
            return "1~2ë…„"
        if "3~5ë…„" in s or "3-5ë…„" in s:
            return "3~5ë…„"
        if "6ë…„ì´ìƒ" in s:
            return "6ë…„ ì´ìƒ"
        return s

    df["experience_years_normalized"] = df["ê³¼ì™¸ ê²½ë ¥ì€ ì–¼ë§ˆë‚˜ ë˜ì‹œë‚˜ìš”?"].apply(normalize_experience)
    df["experience_label"] = df["experience_years_normalized"].map({
        "6ë…„ ì´ìƒ": "A", "3~5ë…„": "B", "1~2ë…„": "C", "1ë…„ ì´í•˜": "D"
    })

    # ì „ì—…/ë¶€ì—… ë¼ë²¨
    df["is_primary_job_label"] = df["í˜„ì¬ ê³¼ì™¸ í™œë™ì€ ë³¸ì—…ì¸ê°€ìš”, ë¶€ì—…ì¸ê°€ìš”?"].map({
        "ì „ì—… (ê³¼ì™¸ê°€ ì£¼ ìˆ˜ì…ì›)": "A", "ë¶€ì—… (ë³¸ì—…ì´ ë”°ë¡œ ìˆìŒ)": "B"
    })

    # ìˆ˜ì—… ë°©ì‹ ë¼ë²¨
    df["teaching_mode_label"] = df["ìˆ˜ì—… ë°©ì‹ì€ ì–´ë–»ê²Œ ì§„í–‰í•˜ì‹œë‚˜ìš”?"].map({
        "ëŒ€ë©´": "A",
        "ëŒ€ë©´ê³¼ ë¹„ëŒ€ë©´ ëª¨ë‘ ê°€ëŠ¥": "A",
        "ë¹„ëŒ€ë©´": "B"
    })

    # ìë£Œ ìœ í˜• ë¼ë²¨
    def label_material_type(cell):
        if pd.isna(cell):
            return "B"
        return "A" if "ìì²´ ì œì‘" in str(cell) else "B"

    df["material_label"] = df["ìˆ˜ì—… ì¤‘ ì œê³µí•˜ëŠ” ìë£Œ ìœ í˜•ì„ ëª¨ë‘ ì„ íƒí•´ì£¼ì„¸ìš”."].apply(label_material_type)

    # í•™ìƒ ìˆ˜ ì •ìˆ˜í™”
    def clean_student_count(text):
        if pd.isna(text):
            return np.nan
        cleaned = re.sub(r"[^\d]", "", str(text))
        return int(cleaned) if cleaned else np.nan

    df["students_total_label"] = df["ì§€ê¸ˆê¹Œì§€ ê°€ë¥´ì¹œ í•™ìƒ ìˆ˜ëŠ” ëª‡ ëª…ì¸ê°€ìš”? (ìˆ«ìë§Œ ì…ë ¥í•´ì£¼ì„¸ìš”)"].apply(clean_student_count)

    # ëŒ€í•™ ë¶„ë¥˜ (ì´ì œ í•˜ë‚˜ì˜ í•¨ìˆ˜ ì‚¬ìš©)
    df[["univ_normalized", "univ_tier", "univ_tier_score"]] = df["í•™êµëª…ì„ ê¸°ì…í•´ì£¼ì„¸ìš”.(ì¬í•™ì¤‘ í¬í•¨)"].apply(
        lambda x: pd.Series(classify_univ(x))
    )

    # ê°€ë¥´ì¹˜ëŠ” ì—°ë ¹ëŒ€ ë©€í‹°í•«
    AGE_LABELS = {
        "íŒŒì´ë„ ì…ì‹œ ì¤€ë¹„ìƒ": "age_final",
        "ì„±ì¸": "age_adult",
        "ê³ ë“±í•™ìƒ": "age_high",
        "ì¤‘í•™ìƒ": "age_middle",
        "ì´ˆë“±í•™ìƒ": "age_elementary"
    }

    def multihot(cell):
        if pd.isna(cell):
            return []
        items = [x.strip() for x in str(cell).split(",")]
        return [AGE_LABELS[i] for i in items if i in AGE_LABELS]

    df["student_age_label"] = df["ê°€ë¥´ì¹˜ëŠ” í•™ìƒ ì—°ë ¹ëŒ€ë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”."].apply(multihot)
    for lbl in AGE_LABELS.values():
        df[lbl] = df["student_age_label"].apply(lambda lst: int(lbl in lst))

    df.to_csv("survey_clean.csv", index=False)
    return df

# =============================
# ëª¨ë¸ í•™ìŠµ (Train/Test ë¶„ë¦¬, ìºì‹œ)
# =============================
@st.cache_resource
def train_model(df: pd.DataFrame):
    df = df.dropna(subset=["log_hourly_won_clean"])

    # --- Feature sets ---
    categorical = [
        "experience_label",
        "major_match_label",
        "is_primary_job_label",
        "teaching_mode_label",
        "material_label",
        "univ_tier"  # â† ìˆ«ì(ì ìˆ˜) ëŒ€ì‹  ë²”ì£¼í˜•ìœ¼ë¡œ ì‚¬ìš©
    ]
    numeric = ["students_total_label"]
    multi = ["age_final", "age_adult", "age_high", "age_middle", "age_elementary"]
    target = "log_hourly_won_clean"

    X = df[categorical + numeric + multi]
    y = df[target]

    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, random_state=42
    )

    preprocessor = ColumnTransformer([
        ("cat", OneHotEncoder(handle_unknown="ignore"), categorical),
        ("num", SimpleImputer(strategy="mean"), numeric)
    ], remainder="passthrough")

    pipeline = Pipeline([
        ("preprocessor", preprocessor),
        ("regressor", LinearRegression())
    ])

    pipeline.fit(X_train, y_train)

    # í‰ê°€
    y_pred_test = pipeline.predict(X_test)
    rmse = float(np.sqrt(mean_squared_error(y_test, y_pred_test)))
    r2 = float(r2_score(y_test, y_pred_test))
    metrics = {"rmse": rmse, "r2": r2, "trained_at": datetime.now().isoformat()}

    return pipeline, metrics, categorical, numeric, multi

# =============================
# MAIN
# =============================
df = clean_data(RAW_FILE)
pipeline, metrics, CAT_COLS, NUM_COLS, MULTI_COLS = train_model(df)

# =============================
# UI
# =============================
st.title("ğŸ“Š í”„ë¦¬ëœì„œ ê°•ì‚¬ ì‹œê¸‰ ì˜ˆì¸¡ê¸°")
st.caption("UI ì…ë ¥ê°’ì€ í•™ìŠµì— ì‚¬ìš©ë˜ì§€ ì•Šê³ , **ì´ë¯¸ í•™ìŠµëœ ëª¨ë¸ë¡œ ì¶”ë¡ ë§Œ** ìˆ˜í–‰í•©ë‹ˆë‹¤.")

with st.expander("ğŸ“ˆ í˜„ì¬ ëª¨ë¸ í…ŒìŠ¤íŠ¸ ì„±ëŠ¥", expanded=False):
    st.write(f"**RMSE**: {metrics['rmse']:,.2f}")
    st.write(f"**RÂ²**: {metrics['r2']:.4f}")
    st.write(f"Trained at: {metrics['trained_at']}")

# 1. ê²½ë ¥
exp_options = {"6ë…„ ì´ìƒ": "A", "3~5ë…„": "B", "1~2ë…„": "C", "1ë…„ ì´í•˜": "D"}
exp_kor = st.selectbox("ê³¼ì™¸ ê²½ë ¥", list(exp_options.keys()))
exp = exp_options[exp_kor]

# 2. ì „ê³µ ì—°ê´€ì„±
match_options = {"ë§¤ìš° ë†’ìŒ": "A", "ë†’ìŒ": "B", "ë³´í†µ": "C", "ë‚®ìŒ": "D", "ì „í˜€ ì—†ìŒ": "E"}
match_kor = st.selectbox("ì „ê³µê³¼ ê³¼ì™¸ ê³¼ëª©ì˜ ì—°ê´€ì„±", list(match_options.keys()))
match = match_options[match_kor]

# 3. ì „ì—…/ë¶€ì—…
jobtype_options = {"ì „ì—… (ê³¼ì™¸ê°€ ì£¼ ìˆ˜ì…ì›)": "A", "ë¶€ì—… (ë³¸ì—…ì´ ë”°ë¡œ ìˆìŒ)": "B"}
jobtype_kor = st.selectbox("ê³¼ì™¸ í™œë™ ìœ í˜•", list(jobtype_options.keys()))
jobtype = jobtype_options[jobtype_kor]

# 4. ìˆ˜ì—… ë°©ì‹
mode_options = {"ëŒ€ë©´ / ëŒ€ë©´+ë¹„ëŒ€ë©´ ëª¨ë‘ ê°€ëŠ¥": "A", "ë¹„ëŒ€ë©´ë§Œ ê°€ëŠ¥": "B"}
mode_kor = st.selectbox("ìˆ˜ì—… ë°©ì‹", list(mode_options.keys()))
mode = mode_options[mode_kor]

# 5. ìë£Œ ì œê³µ ìœ í˜•
material_options = {"ìì²´ ì œì‘ ìë£Œ ì œê³µ": "A", "ê¸°ì„± ìë£Œ ë˜ëŠ” ë¯¸ì œê³µ": "B"}
material_kor = st.selectbox("ìë£Œ ìœ í˜•", list(material_options.keys()))
material = material_options[material_kor]

# 6. ëˆ„ì  í•™ìƒ ìˆ˜
students = st.number_input("ëˆ„ì  í•™ìƒ ìˆ˜", min_value=0, step=1)

# 7. ëŒ€í•™ ì…ë ¥ & ë¶„ë¥˜
raw_school = st.text_input("í•™êµëª…ì„ ì…ë ¥í•˜ì„¸ìš” (ì˜ˆ: ì„œìš¸ëŒ€, ì—°ì„¸ëŒ€í•™êµ ë“±)")
normalized_name, tier_letter, tier_score = classify_univ(raw_school)
st.write(f"ğŸ“ ë¶„ë¥˜: {normalized_name} / í‹°ì–´ {tier_letter} / ì ìˆ˜ {tier_score}")

# 8. ì—°ë ¹ëŒ€
st.write("í•™ìƒ ì—°ë ¹ëŒ€ (ë³µìˆ˜ ì„ íƒ ê°€ëŠ¥)")
age_final = st.checkbox("ì…ì‹œ ì¤€ë¹„ìƒ")
age_adult = st.checkbox("ì„±ì¸")
age_high = st.checkbox("ê³ ë“±í•™ìƒ")
age_middle = st.checkbox("ì¤‘í•™ìƒ")
age_elementary = st.checkbox("ì´ˆë“±í•™ìƒ")

# 9. ì‹¤ì œ ì‹œê¸‰(ì„ íƒ)
actual_hourly = st.number_input("í˜„ì¬ ë°›ê³  ìˆëŠ” ì‹œê¸‰ì„ ì…ë ¥í•´ì£¼ì„¸ìš” (ì„ íƒ)", min_value=0, step=1000)

# ì˜ˆì¸¡
if st.button("ğŸ’¡ ì˜ˆì¸¡ ì‹¤í–‰"):
    input_df = pd.DataFrame([{
        "experience_label": exp,
        "major_match_label": match,
        "is_primary_job_label": jobtype,
        "teaching_mode_label": mode,
        "material_label": material,
        "univ_tier": tier_letter,
        "students_total_label": students,
        "age_final": int(age_final),
        "age_adult": int(age_adult),
        "age_high": int(age_high),
        "age_middle": int(age_middle),
        "age_elementary": int(age_elementary)
    }])

    pred_log = pipeline.predict(input_df)[0]
    pred_won = int(np.expm1(pred_log))
    st.success(f"ğŸ’° ì˜ˆì¸¡ëœ ì‹œê¸‰: â‚©{pred_won:,}")

    # ì €ì¥í•  ë°ì´í„° (ì›í•˜ë©´ í—¤ë” í–‰ ë¯¸ë¦¬ ë§Œë“¤ì–´ë‘ëŠ” ê±¸ ê¶Œì¥)
    user_data_row = [
        datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
        raw_school,
        normalized_name,
        tier_letter,
        tier_score,
        exp_kor, exp,
        match_kor, match,
        jobtype_kor, jobtype,
        mode_kor, mode,
        material_kor, material,
        students,
        int(age_final), int(age_adult), int(age_high), int(age_middle), int(age_elementary),
        actual_hourly,
        float(pred_log),
        pred_won
    ]

    # Google Sheets ì €ì¥
    try:
        scope = ["https://spreadsheets.google.com/feeds", "https://www.googleapis.com/auth/drive"]
        creds = ServiceAccountCredentials.from_json_keyfile_dict(st.secrets["gcp_service_account"], scope)
        client = gspread.authorize(creds)
        sheet = client.open("Tutorpays Submissions").sheet1
        sheet.append_row(user_data_row)
        st.info("âœ… Google Sheets ì €ì¥ ì™„ë£Œ")
    except Exception as e:
        st.warning(f"Google Sheets ì €ì¥ ì‹¤íŒ¨: {e}")

    # ë¡œì»¬ CSV ì €ì¥
    try:
        with open("form_submissions.csv", "a", newline="", encoding="utf-8") as f:
            writer = csv.writer(f)
            writer.writerow(user_data_row)
        st.info("âœ… ë¡œì»¬ CSV ì €ì¥ ì™„ë£Œ")
    except Exception as e:
        st.warning(f"CSV ì €ì¥ ì‹¤íŒ¨: {e}")
